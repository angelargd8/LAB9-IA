{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15ab2f5d",
   "metadata": {},
   "source": [
    "# Laboratorio 9 \n",
    "\n",
    "Francis Aguilar #22243  \n",
    "Angela García #22869  \n",
    "Gerardo Pineda #22808  \n",
    "\n",
    "Enlace del repositorio: https://github.com/angelargd8/LAB9-IA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e43e8e4",
   "metadata": {},
   "source": [
    "# Task 1. Preguntas de Teoría"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd05c272",
   "metadata": {},
   "source": [
    "## 1. Diferencias entre modelos de Markov y Hidden Markov Models\n",
    "\n",
    "\n",
    "| Modelos de Markov     | Hidden Markokv Models    |\n",
    "|--------------------|--------------------|\n",
    "| - Todos los estados son completamente observables | - Los estados no son observables, se puede ver una secuencia de señales que dan pistas del estado |\n",
    "| - En la estimación de parametros, las probabilidades de transición pueden ser estimadas por la secuencia de los estados observables| - La estimación involucra el algoritmos como Baum- Welch algorithm que iterativamente ajusta los parametros del modelo para maximizar la probabilidad de la secuencia observada del modelo |\n",
    "| - las predicciones del futuro estado del modelo depende del estado actual, no en la ruta tomada| - las predicciones dependen de los resultados observables, que dan la información acerca de la ruta de los estados escondidos |\n",
    "| - es menos complejo, tiene pocos parametros de probabilidades de transición | - es más complejo, require de transición, emisión, y las probabilidades iniciales del estado |\n",
    "| - Su aplicación puede ser en juegos de mesa, predicción meteorológica y para sistemas transparentes| - es ideal para procesos en donde los estados se infieren a través de sus resultados, como reconocimiento de voz, o análisis de secuencia génetica|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89dc4704",
   "metadata": {},
   "source": [
    "## 2. Qué son los factorial HMM (Hidden Markov Models)\n",
    "- Los factorial HMM son una extensión de los modelos de HMM, que están diseñados para abordar problemas más complejos al descomoponer el estado oculto en múltiples factores independientes. Y los factores se combinan para generar las observacones. Entonces un FHMM se divide en varios sub-estados o factores independientes cada uno con su propio proceso de Markov. Estos son utiles para modelar sistemas en donde las observacioens dependen de múltiples causas independientes, como el reconocimiento de actividad humana, ya que pueden representar diferentes acciones como es caminar, hablar y otros. Que interactuan para generar una señal observable.  Y estos tienen una mayor capacidad para capturar estructuras complejas y relaciones en los datos. Sin embargo, hay que tomar en cuenta que por los múltiples factores y su interacción, el entrenamiento e inferencia son más costosos computacionalmente hablando.  \n",
    "\n",
    "## 3. El algoritmo Foward Backward para HMM\n",
    "- El algoritmo Foward Backward para HMM es un método importante para los modelos de HMM, ya que este permite calcular de una manera eficiente las probabilidades de los estados ocultos dadas las observaciones y en este se usan tareas de inferencia para hacer una decodificación suave para determinar la probabilidad de que el modelo se encuentre en un estado específico en un momento dado. \n",
    "\n",
    "## 4. ¿Por qué es necesario el paso de Backward? en el algoritmo backward. Con una caso de ejemplo.\n",
    "-  Es necesario el paso de Backward porque permite calcular las probabilidades de los estados ocultos considerando toda la secuencia de observaciones y no solo las observaviones anteriores al momento actual. Un caso de ejemplo puede ser el jugar AmongUs, porque estamos buscando al impostor y no solo nos podemos basar en la última acción sospechosa del jugador que estamos acusando que es el impostor. Entonces nos basamos en quien estaba por el lugar que mataron al otro jugador y las acciones que este realizo anteriormente para poder votar. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1785412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Secuencia Generada: ['Sunny', 'Rainy', 'Rainy', 'Rainy', 'Rainy']\n",
      "\n",
      "Probabilidades Forward:\n",
      "t=0: {'Sunny': 0.4, 'Rainy': 0.15}\n",
      "t=1: {'Sunny': 0.07600000000000001, 'Rainy': 0.119}\n",
      "t=2: {'Sunny': 0.021680000000000005, 'Rainy': 0.06061999999999999}\n",
      "t=3: {'Sunny': 0.008318400000000002, 'Rainy': 0.028495599999999992}\n",
      "t=4: {'Sunny': 0.003610592, 'Rainy': 0.013132727999999996}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "class HMM:\n",
    "    def __init__(self, states, observations, initial_prob, transition_prob, emission_prob):\n",
    "        self.states = states\n",
    "        self.observations = observations\n",
    "        self.initial_prob = initial_prob\n",
    "        self.transition_prob = transition_prob\n",
    "        self.emission_prob = emission_prob\n",
    "\n",
    "    def generate_sequence(self, length):\n",
    "        sequence = []\n",
    "        current_state = random.choices(self.states, weights=[self.initial_prob[s] for s in self.states])[0]\n",
    "        for _ in range(length):\n",
    "            observation = random.choices(self.observations, weights=[self.emission_prob[current_state][o] for o in self.observations])[0]\n",
    "            sequence.append(observation)\n",
    "            current_state = random.choices(self.states, weights=[self.transition_prob[current_state][s] for s in self.states])[0]\n",
    "        return sequence\n",
    "\n",
    "    def forward(self, observations):\n",
    "        alpha = [{}]\n",
    "\n",
    "        for state in self.states:\n",
    "            alpha[0][state] = self.initial_prob[state] * self.emission_prob[state][observations[0]]\n",
    "\n",
    "        for t in range(1, len(observations)):\n",
    "            alpha.append({})\n",
    "            for curr_state in self.states:\n",
    "                sum_prob = sum(alpha[t-1][prev_state] * self.transition_prob[prev_state][curr_state] for prev_state in self.states)\n",
    "                alpha[t][curr_state] = sum_prob * self.emission_prob[curr_state][observations[t]]\n",
    "        \n",
    "        return alpha\n",
    "\n",
    "    def backward(self, observations):\n",
    "        pass\n",
    "        # beta = [{} for _ in range(len(observations))]\n",
    "\n",
    "        # for state in self.states:\n",
    "        #     beta[-1][state] = 1\n",
    "\n",
    "        # for t in range(len(observations) - 2, -1, -1):\n",
    "        #     for curr_state in self.states:\n",
    "        #         beta[t][curr_state] = sum(\n",
    "        #             self.transition_prob[curr_state][next_state] *\n",
    "        #             self.emission_prob[next_state][observations[t+1]] *\n",
    "        #             beta[t+1][next_state]\n",
    "        #             for next_state in self.states\n",
    "        #         )\n",
    "        \n",
    "        # return beta\n",
    "\n",
    "    def compute_state_probabilities(self, observations):\n",
    "        pass\n",
    "        # forward_probs = self.forward(observations)\n",
    "        # backward_probs = self.backward(observations)\n",
    "        # state_probs = []\n",
    "\n",
    "        # for t in range(len(observations)):\n",
    "        #     probs = {}\n",
    "        #     total = sum(forward_probs[t][state] * backward_probs[t][state] for state in self.states)\n",
    "        #     for state in self.states:\n",
    "        #         probs[state] = (forward_probs[t][state] * backward_probs[t][state]) / total\n",
    "        #     state_probs.append(probs)\n",
    "\n",
    "        # return state_probs\n",
    "\n",
    "# Uso del modelo\n",
    "states = ['Sunny', 'Rainy']\n",
    "observations = ['Sunny', 'Rainy']\n",
    "initial_prob = {'Sunny': 0.5, 'Rainy': 0.5}\n",
    "transition_prob = {\n",
    "    'Sunny': {'Sunny': 0.8, 'Rainy': 0.2},\n",
    "    'Rainy': {'Sunny': 0.4, 'Rainy': 0.6}\n",
    "}\n",
    "emission_prob = {\n",
    "    'Sunny': {'Sunny': 0.8, 'Rainy': 0.2},\n",
    "    'Rainy': {'Sunny': 0.3, 'Rainy': 0.7}\n",
    "}\n",
    "\n",
    "# Instanciar el modelo\n",
    "hmm = HMM(states, observations, initial_prob, transition_prob, emission_prob)\n",
    "\n",
    "# Generar una secuencia de observaciones\n",
    "obs_sequence = hmm.generate_sequence(5)\n",
    "print(\"\\nSecuencia Generada:\", obs_sequence)\n",
    "\n",
    "# Calcular probabilidades hacia adelante\n",
    "forward_probs = hmm.forward(obs_sequence)\n",
    "print(\"\\nProbabilidades Forward:\")\n",
    "for t, probs in enumerate(forward_probs):\n",
    "    print(f\"t={t}: {probs}\")\n",
    "\n",
    "# # Calcular probabilidades hacia atrás\n",
    "# backward_probs = hmm.backward(obs_sequence)\n",
    "# print(\"\\nProbabilidades Backward:\")\n",
    "# for t, probs in enumerate(backward_probs):\n",
    "#     print(f\"t={t}: {probs}\")\n",
    "\n",
    "# # # Calcular las probabilidades de estado\n",
    "# state_probs = hmm.compute_state_probabilities(obs_sequence)\n",
    "# print(\"\\nProbabilidades de Estados:\")\n",
    "# for t, probs in enumerate(state_probs):\n",
    "#     print(f\"t={t}: {probs}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
